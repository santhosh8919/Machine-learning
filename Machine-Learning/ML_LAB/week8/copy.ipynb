{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Import required libraries (Done above)\n",
    "\n",
    "# 2. Import 20news group dataset from scikit-learn datasets\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# 3. Load 20news group train subset\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# 4. Load 20news group test subset\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# 5. Print all target labels\n",
    "print(\"Target Labels:\", train_data.target_names)\n",
    "\n",
    "# 6. Prepare subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# 7. Load 20news group train subset with three categories\n",
    "train_subset = fetch_20newsgroups(subset='train', categories=categories)\n",
    "\n",
    "# 8. Load 20news group test subset with three categories\n",
    "test_subset = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "# 9. Print new training set target names (Labels)\n",
    "print(\"New Training Set Labels:\", train_subset.target_names)\n",
    "\n",
    "# 10. Print news training data of the 5th article\n",
    "print(\"5th Training Article:\\n\", train_subset.data[4])\n",
    "\n",
    "# 11. Print shape of data and targets\n",
    "print(\"Train Data Shape:\", len(train_subset.data))\n",
    "print(\"Train Target Shape:\", len(train_subset.target))\n",
    "\n",
    "# 12. Print training set filenames\n",
    "print(\"Training Set Filenames:\", train_subset.filenames[:5])\n",
    "\n",
    "# 13. By using CountVectorizer, train data into numerical format\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(train_subset.data)\n",
    "\n",
    "# 14. Use BernoulliNB for training\n",
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_nb.fit(X_train_counts, train_subset.target)\n",
    "\n",
    "# 15. By using CountVectorizer, convert test data into numeric format\n",
    "X_test_counts = count_vectorizer.transform(test_subset.data)\n",
    "\n",
    "# 16. Predict target labels for testing set\n",
    "y_pred = bernoulli_nb.predict(X_test_counts)\n",
    "\n",
    "# 17. Find accuracy score on test set\n",
    "accuracy = accuracy_score(test_subset.target, y_pred)\n",
    "print(\"BernoulliNB Accuracy:\", accuracy)\n",
    "\n",
    "# 18. Use TfidfVectorizer instead of CountVectorizer and use MultinomialNB\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_subset.data)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_subset.data)\n",
    "multinomial_nb = MultinomialNB()\n",
    "multinomial_nb.fit(X_train_tfidf, train_subset.target)\n",
    "\n",
    "# 19. Find test set accuracy\n",
    "y_pred_tfidf = multinomial_nb.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(test_subset.target, y_pred_tfidf)\n",
    "print(\"MultinomialNB Accuracy:\", accuracy_tfidf)\n",
    "\n",
    "# 20. Try avoiding stopwords and repeat the same\n",
    "tfidf_vectorizer_stopwords = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf_sw = tfidf_vectorizer_stopwords.fit_transform(train_subset.data)\n",
    "X_test_tfidf_sw = tfidf_vectorizer_stopwords.transform(test_subset.data)\n",
    "multinomial_nb_sw = MultinomialNB()\n",
    "multinomial_nb_sw.fit(X_train_tfidf_sw, train_subset.target)\n",
    "\n",
    "y_pred_tfidf_sw = multinomial_nb_sw.predict(X_test_tfidf_sw)\n",
    "accuracy_tfidf_sw = accuracy_score(test_subset.target, y_pred_tfidf_sw)\n",
    "print(\"MultinomialNB Accuracy (with stopwords removed):\", accuracy_tfidf_sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"/mnt/data/nlp_train.csv\")\n",
    "test_df = pd.read_csv(\"/mnt/data/nlp_test.csv\")\n",
    "\n",
    "# Print all target labels\n",
    "print(\"Unique target labels:\", train_df['category'].unique())\n",
    "\n",
    "# Select subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "train_df = train_df[train_df['category'].isin(categories)]\n",
    "test_df = test_df[test_df['category'].isin(categories)]\n",
    "\n",
    "# Print new training set target names\n",
    "print(\"Filtered target labels:\", train_df['category'].unique())\n",
    "\n",
    "# Print training data of the 5th article\n",
    "print(\"5th article text:\", train_df.iloc[4]['text'])\n",
    "\n",
    "# Print shape of data and targets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Testing set shape:\", test_df.shape)\n",
    "\n",
    "# Print training set filenames (if available)\n",
    "if 'filename' in train_df.columns:\n",
    "    print(\"Training filenames:\", train_df['filename'].head())\n",
    "\n",
    "# Convert text to numerical format using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(train_df['text'])\n",
    "X_test_counts = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Convert labels to numerical format\n",
    "y_train = train_df['category']\n",
    "y_test = test_df['category']\n",
    "\n",
    "# Train Bernoulli Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predict target labels for test set\n",
    "y_pred = bnb.predict(X_test_counts)\n",
    "\n",
    "# Find accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy using BernoulliNB:\", accuracy)\n",
    "\n",
    "# Use TfidfVectorizer instead of CountVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Train Multinomial Naive Bayes model\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "y_pred_tfidf = mnb.predict(X_test_tfidf)\n",
    "tfidf_accuracy = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(\"Accuracy using MultinomialNB with TF-IDF:\", tfidf_accuracy)\n",
    "\n",
    "# Try avoiding stopwords and repeat the same\n",
    "vectorizer_stop = CountVectorizer(stop_words='english')\n",
    "X_train_counts_stop = vectorizer_stop.fit_transform(train_df['text'])\n",
    "X_test_counts_stop = vectorizer_stop.transform(test_df['text'])\n",
    "\n",
    "bnb_stop = BernoulliNB()\n",
    "bnb_stop.fit(X_train_counts_stop, y_train)\n",
    "y_pred_stop = bnb_stop.predict(X_test_counts_stop)\n",
    "stopword_accuracy = accuracy_score(y_test, y_pred_stop)\n",
    "print(\"Accuracy using BernoulliNB with stopwords removed:\", stopword_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV files\n",
    "train_file_path = \"/mnt/data/newsgroups_train.csv\"\n",
    "test_file_path = \"/mnt/data/newsgroups_test.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "train_data.info(), test_data.info(), train_data.head(), test_data.head()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Import required libraries (already done)\n",
    "\n",
    "# Step 2: Prepare subsets of categories\n",
    "selected_categories = [\"alt.atheism\", \"comp.graphics\", \"sci.space\"]\n",
    "train_subset = train_data[train_data[\"category\"].isin(selected_categories)]\n",
    "test_subset = test_data[test_data[\"category\"].isin(selected_categories)]\n",
    "\n",
    "# Step 3: Print all target labels in the training set\n",
    "target_labels = train_subset[\"target\"].unique()\n",
    "\n",
    "# Step 4: Print new training set target names (Labels)\n",
    "target_names = train_subset[\"category\"].unique()\n",
    "\n",
    "# Step 5: Print news training data of the 5th article\n",
    "fifth_article = train_subset.iloc[4][\"text\"]\n",
    "\n",
    "# Step 6: Print shape of data and targets\n",
    "train_shape = train_subset.shape\n",
    "test_shape = test_subset.shape\n",
    "\n",
    "# Step 7: Print training set filenames (not applicable since no filenames column)\n",
    "\n",
    "# Step 8: Convert text data into numerical format using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(train_subset[\"text\"])\n",
    "X_test_counts = count_vectorizer.transform(test_subset[\"text\"])\n",
    "\n",
    "# Step 9: Train using BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_counts, train_subset[\"target\"])\n",
    "\n",
    "# Step 10: Convert test data into numerical format using CountVectorizer\n",
    "X_test_counts = count_vectorizer.transform(test_subset[\"text\"])\n",
    "\n",
    "# Step 11: Predict target labels for the testing set\n",
    "bnb_predictions = bnb.predict(X_test_counts)\n",
    "\n",
    "# Step 12: Find accuracy score on the test set\n",
    "bnb_accuracy = accuracy_score(test_subset[\"target\"], bnb_predictions)\n",
    "\n",
    "# Step 13: Use TfidfVectorizer instead of CountVectorizer and train MultinomialNB\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_subset[\"text\"])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_subset[\"text\"])\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, train_subset[\"target\"])\n",
    "\n",
    "# Step 14: Predict target labels using MultinomialNB\n",
    "mnb_predictions = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Step 15: Find test set accuracy for MultinomialNB\n",
    "mnb_accuracy = accuracy_score(test_subset[\"target\"], mnb_predictions)\n",
    "\n",
    "# Step 16: Try with avoiding stopwords and repeat the same process\n",
    "count_vectorizer_stopwords = CountVectorizer(stop_words='english')\n",
    "X_train_counts_sw = count_vectorizer_stopwords.fit_transform(train_subset[\"text\"])\n",
    "X_test_counts_sw = count_vectorizer_stopwords.transform(test_subset[\"text\"])\n",
    "\n",
    "bnb_sw = BernoulliNB()\n",
    "bnb_sw.fit(X_train_counts_sw, train_subset[\"target\"])\n",
    "bnb_sw_predictions = bnb_sw.predict(X_test_counts_sw)\n",
    "bnb_sw_accuracy = accuracy_score(test_subset[\"target\"], bnb_sw_predictions)\n",
    "\n",
    "# Prepare results\n",
    "{\n",
    "    \"Target Labels\": target_labels,\n",
    "    \"Target Names\": target_names,\n",
    "    \"5th Article\": fifth_article[:500],  # Limiting to 500 characters for display\n",
    "    \"Train Shape\": train_shape,\n",
    "    \"Test Shape\": test_shape,\n",
    "    \"BernoulliNB Accuracy\": bnb_accuracy,\n",
    "    \"MultinomialNB Accuracy\": mnb_accuracy,\n",
    "    \"BernoulliNB Accuracy (with stopwords removed)\": bnb_sw_accuracy\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load 20 News Groups dataset (train and test)\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print all target labels\n",
    "target_labels = list(newsgroups_train.target_names)\n",
    "print(\"Target Labels:\", target_labels)\n",
    "\n",
    "# Print new training set target names\n",
    "print(\"Training Target Names:\", np.unique(newsgroups_train.target))\n",
    "\n",
    "# Print 5th article text\n",
    "print(\"\\n5th Training Article:\\n\", newsgroups_train.data[4][:500], \"...\")  # Limited display\n",
    "\n",
    "# Print shapes of data and targets\n",
    "print(\"\\nTrain Data Shape:\", len(newsgroups_train.data), \"Train Target Shape:\", len(newsgroups_train.target))\n",
    "print(\"Test Data Shape:\", len(newsgroups_test.data), \"Test Target Shape:\", len(newsgroups_test.target))\n",
    "\n",
    "# Convert text data to numerical format using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test_counts = count_vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Train Naive Bayes classifier using BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_counts, newsgroups_train.target)\n",
    "\n",
    "# Convert test data into numeric format using CountVectorizer\n",
    "X_test_counts = count_vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Predict target labels for test set\n",
    "y_pred_bnb = bnb.predict(X_test_counts)\n",
    "\n",
    "# Find accuracy score on test set using BernoulliNB\n",
    "accuracy_bnb = accuracy_score(newsgroups_test.target, y_pred_bnb)\n",
    "print(\"\\nAccuracy using BernoulliNB:\", accuracy_bnb)\n",
    "\n",
    "# Use TfidfVectorizer instead of CountVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Train Naive Bayes classifier using MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for test set\n",
    "y_pred_mnb = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Find accuracy score using MultinomialNB\n",
    "accuracy_mnb = accuracy_score(newsgroups_test.target, y_pred_mnb)\n",
    "print(\"Accuracy using MultinomialNB:\", accuracy_mnb)\n",
    "\n",
    "# Avoid stopwords and repeat the process\n",
    "tfidf_vectorizer_sw = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf_sw = tfidf_vectorizer_sw.fit_transform(newsgroups_train.data)\n",
    "X_test_tfidf_sw = tfidf_vectorizer_sw.transform(newsgroups_test.data)\n",
    "\n",
    "# Train MultinomialNB with stopwords removed\n",
    "mnb_sw = MultinomialNB()\n",
    "mnb_sw.fit(X_train_tfidf_sw, newsgroups_train.target)\n",
    "\n",
    "# Predict test labels with stopwords removed\n",
    "y_pred_mnb_sw = mnb_sw.predict(X_test_tfidf_sw)\n",
    "\n",
    "# Find accuracy with stopwords removed\n",
    "accuracy_mnb_sw = accuracy_score(newsgroups_test.target, y_pred_mnb_sw)\n",
    "print(\"Accuracy using MultinomialNB (without stopwords):\", accuracy_mnb_sw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
